/** @file    imopv.tc
 ** @author  Andrea Vedaldi
 ** @brief   Vectorized image operations - Definition Template
 **/

/* AUTORIGHTS
 Copyright (C) 2007-09 Andrea Vedaldi and Brian Fulkerson

 This file is part of VLFeat, available in the terms of the GNU
 General Public License version 2.
 */

#define JOIN_(a,b) a ## b
#define JOIN(a,b) JOIN_(a,b)
#define JOIN3_(a,b,c) a ## b ## c
#define JOIN3(a,b,c) JOIN3_(a,b,c)

#undef  FLT
#undef  VSIZE
#undef  SFX
#undef  VTYPE
#undef  ALIGNPTR
#undef  ALIGNSTRIDE
#undef  VL_IMCONVCOL
#undef  VL_IMCONVCOLTRI

#if (FLOAT_TYPE == FLOAT_TYPE_FLOAT)
#  define FLT    float
#  define VSIZE  4
#  define SFX    vf
#  define VTYPE  __m128
#else
#  define FLT    double
#  define VSFX   pd
#  define SFX    vd
#  define VTYPE  __m128d
#endif

#define ALIGNPTR        (sizeof(FLT) * VSIZE - 1)
#define ALIGNSTRIDE     (VSIZE - 1)
#define VL_IMCONVCOL    JOIN(vl_imconvcol_,    SFX)
#define VL_IMCONVCOLTRI JOIN(vl_imconvcoltri_, SFX)

/* ---------------------------------------------------------------- */
VL_EXPORT
void
VL_IMCONVCOL (FLT* dst, int dst_stride,
              FLT const* src,
              int src_width, int src_height, int src_stride,
              FLT const* filt, int filt_begin, int filt_end,
              int step, unsigned int flags)
{
  int x = 0 ;
  int y ;
  int dheight = (src_height - 1) / step + 1 ;
  vl_bool transp = flags & VL_TRANSPOSE ;
  vl_bool zeropad = (flags & VL_PAD_MASK) == VL_PAD_BY_ZERO ;

  /* dispatch to accelerated version */
#ifdef VL_SUPPORT_SSE2
  if (vl_cpu_has_sse2() && vl_get_simd_enabled()) {
    JOIN3(_,VL_IMCONVCOL,_sse2)
    (dst,dst_stride,
     src,src_width,src_height,src_stride,
     filt,filt_begin,filt_end,
     step,flags) ;
    return ;
  }
#endif

  /* let filt point to the last sample of the filter */
  filt += filt_end - filt_begin ;

  while (x < src_width) {
    /* Calculate dest[x,y] = sum_p image[x,p] filt[y - p]
     * where supp(filt) = [filt_begin, filt_end] = [fb,fe].
     *
     * CHUNK_A: y - fe <= p < 0
     *          completes VL_MAX(fe - y, 0) samples
     * CHUNK_B: VL_MAX(y - fe, 0) <= p < VL_MIN(y - fb, height - 1)
     *          completes fe - VL_MAX(fb, height - y) + 1 samples
     * CHUNK_C: completes all samples
     */
    FLT const *filti ;
    int stop ;

    for (y = 0 ; y < src_height ; y += step) {
      FLT acc = 0 ;
      FLT v = 0, c ;
      FLT const* srci ;

      filti = filt ;
      stop = filt_end - y ;
      srci = src + x - stop * src_stride ;

      if (stop > 0) {
        if (zeropad) {
          v = 0 ;
        } else {
          v = *(src + x) ;
        }
        while (filti > filt - stop) {
          c = *filti-- ;
          acc += v * c ;
          srci += src_stride ;
        }
      }

      stop = filt_end - VL_MAX(filt_begin, y - src_height + 1) + 1 ;
      while (filti > filt - stop) {
        v = *srci ;
        c = *filti-- ;
        acc += v * c ;
        srci += src_stride ;
      }

      if (zeropad) v = 0 ;

      stop = filt_end - filt_begin + 1 ;
      while (filti > filt - stop) {
        c = *filti-- ;
        acc += v * c ;
      }

      if (transp) {
        *dst = acc ; dst += 1 ;
      } else {
        *dst = acc ; dst += dst_stride ;
      }
    } /* next y */
    if (transp) {
      dst += 1 * dst_stride - dheight * 1 ;
    } else {
      dst += 1 * 1 - dheight * dst_stride ;
    }
    x += 1 ;
  } /* next x */
}


/* ---------------------------------------------------------------- */
VL_EXPORT
void
VL_IMCONVCOLTRI (FLT* dst, int dst_stride,
                 FLT const* src,
                 int src_width, int src_height, int src_stride,
                 int filt_size,
                 int step, unsigned int flags)
{
  int x = 0 ;
  int y ;
  int dheight = (src_height - 1) / step + 1 ;
  vl_bool transp = flags & VL_TRANSPOSE ;
  vl_bool zeropad = (flags & VL_PAD_MASK) == VL_PAD_BY_ZERO ;
#define fa ((double)(filt_size))
  FLT scale = ((FLT) (1.0/(fa*fa))) ;
  FLT * buff = vl_malloc(sizeof(FLT) * (src_height + filt_size)) ;
  buff += filt_size ;

  while (x < src_width) {
    FLT const *srci ;
    srci = src + x + src_stride * (src_height - 1) ;

    /* We decompose the convolution by a triangluar signal as the convolution
     * by two rectangular signals. The rectangular convolutions are computed
     * quickly by computing the integral signals. Each rectangular convolution
     * introduces a delay, which is compensated by convolving each in opposite
     * directions.
     */

    /* integrate backward the column */
    buff [src_height - 1] = *srci ;
    for (y = src_height-2 ; y >=  0 ; --y) {
      srci -= src_stride ;
      buff [y] = buff [y+1] + *srci ;
    }
    if (zeropad) {
      for ( ; y >= - filt_size ; --y) {
        buff [y] = buff [y+1] ;
      }
    } else {
      for ( ; y >= - filt_size ; --y) {
        buff [y] = buff[y+1] + *srci ;
      }
    }

    /* compute the filter forward */
    for (y = - filt_size ; y < src_height - filt_size ; ++y) {
      buff [y] = buff [y] - buff [y + filt_size] ;
    }
    if (! zeropad) {
      for (y = src_height - filt_size ; y < src_height ; ++y) {
        buff [y] = buff [y] - buff [src_height-1]  *
        (src_height - filt_size - y) ;
      }
    }

    /* integrate forward the column */
    for (y = - filt_size + 1 ; y < src_height ; ++y) {
      buff [y] += buff [y - 1] ;
    }

    /* compute the filter backward */
    {
      int stride = transp ? 1 : dst_stride ;
      dst += dheight * stride ;
      for (y = step * (dheight - 1) ; y >= 0 ; y -= step) {
        dst -= stride ;
        *dst = scale * (buff [y] - buff [y - filt_size]) ;
      }
    }
    x += 1 ;
    dst += transp ? dst_stride : 1 ;
  } /* next x */
  vl_free (buff - filt_size) ;
}
